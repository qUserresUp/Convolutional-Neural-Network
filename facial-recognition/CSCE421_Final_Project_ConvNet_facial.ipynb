{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSCE421_Final_Project_ConvNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwV7_6CcwJLU",
        "colab_type": "code",
        "outputId": "97f627d3-99e8-4ee3-9b61-3c68b0765011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1doJD1moswt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ee59f3d-a982-4357-f556-fac43ec28249"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fweZsNM2B8_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "62b55729-0a55-49a8-9f41-24d24ce2243b"
      },
      "source": [
        "\n",
        "%cd /gdrive\n",
        "%cd My\\ Drive\n",
        "%cd CSCE421YaleData \n",
        "!ls"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive\n",
            "/gdrive/My Drive\n",
            "/gdrive/My Drive/CSCE421YaleData\n",
            "csce_421_final_subject_class_emotion.h5    emotions\t\t  subjects\n",
            "csce_421_final_subject_class.h5\t\t   glasses\n",
            "csce_421_final_subject_class_wo_imgAug.h5  Homework5_YaleDataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xlwp1KMq2YrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, shutil\n",
        "\n",
        "original_dataset_dir = '/gdrive/My Drive/CSCE421YaleData/Homework5_YaleDataset'\n",
        "base_dir = '/gdrive/My Drive/CSCE421YaleData/subjects'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-o9md328gh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(base_dir,'train')\n",
        "validation_dir = os.path.join(base_dir,'validation')\n",
        "test_dir = os.path.join(base_dir,'test')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3ynT1N1Un5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "9ed1f41e-c558-4360-aac2-f4dc57bb3001"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\"\"\"\n",
        "======== Model One =======\n",
        "===== overfitting is a big problem =====\n",
        "\n",
        "\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(30, 30, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation = 'relu'))\n",
        "model.add(layers.Dense(15, activation = 'softmax'))\n",
        "model.summary()\n",
        "from keras import optimizers\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer = optimizers.RMSprop(lr=1e-4),\n",
        "              metrics = ['acc'])\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"======Model Two======\"\"\"\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "\"\"\"add dropout to fight overfitting\"\"\"\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(512, activation = 'relu'))\n",
        "model.add(layers.Dense(15, activation = 'softmax'))\n",
        "model.summary()\n",
        "from keras import optimizers\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer = optimizers.RMSprop(lr=1e-4),\n",
        "              metrics = ['acc'])\n",
        "                        "
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 15)                7695      \n",
            "=================================================================\n",
            "Total params: 3,460,303\n",
            "Trainable params: 3,460,303\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81M1eg4OhO7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LF-qG8zloiv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "453e5c87-d913-45a1-9fe3-744c34259485"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\"\"\"Model Two: add data augmentation to generate more samples\"\"\"\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40, \n",
        "    width_shift_range=0.2, \n",
        "    height_shift_range=0.2, \n",
        "    shear_range=0.2, \n",
        "    zoom_range=0.2, \n",
        "    horizontal_flip=True,)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\"\"\"Model Two: change batch_size from 20 to 32\"\"\"\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, \n",
        "    target_size =(150,150), \n",
        "    batch_size=32, \n",
        "    class_mode='categorical') \n",
        "\n",
        "\"\"\"Model Two: change batch_size from 20 to 32\"\"\"\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir, \n",
        "    target_size=(150,150), \n",
        "    batch_size=32, \n",
        "    class_mode='categorical')\n",
        "\n",
        "for data_batch, labels_batch in train_generator:\n",
        "  print('data batch shape:', data_batch.shape)\n",
        "  print('labels batch shape:', labels_batch.shape)\n",
        "  break"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 75 images belonging to 15 classes.\n",
            "Found 45 images belonging to 15 classes.\n",
            "data batch shape: (32, 150, 150, 3)\n",
            "labels batch shape: (32, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mChNvBx5UTWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d43615b-62cd-46e4-ede6-5250ea6014f5"
      },
      "source": [
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator, \n",
        "    steps_per_epoch=50, \n",
        "    epochs=100, \n",
        "    validation_data=validation_generator, \n",
        "    validation_steps=50)\n",
        "\n",
        "model.save('csce_421_final_subject_class_wo_imgAug.h5')\n",
        "\n",
        "\n",
        "# model.load_weights('csce_421_final_subject_class_wo_imgAug.h5')\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 11s 221ms/step - loss: 0.5050 - acc: 0.8290 - val_loss: 1.0687 - val_acc: 0.7556\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 11s 218ms/step - loss: 0.4635 - acc: 0.8625 - val_loss: 0.8062 - val_acc: 0.7556\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.4442 - acc: 0.8396 - val_loss: 0.9015 - val_acc: 0.7556\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.4553 - acc: 0.8608 - val_loss: 1.0417 - val_acc: 0.7333\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 11s 220ms/step - loss: 0.4412 - acc: 0.8576 - val_loss: 0.9934 - val_acc: 0.7778\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.4360 - acc: 0.8495 - val_loss: 1.1649 - val_acc: 0.7333\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.3954 - acc: 0.8673 - val_loss: 0.8788 - val_acc: 0.7778\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 11s 221ms/step - loss: 0.4073 - acc: 0.8672 - val_loss: 0.7747 - val_acc: 0.8444\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.3897 - acc: 0.8750 - val_loss: 0.9299 - val_acc: 0.7556\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.3939 - acc: 0.8589 - val_loss: 0.7526 - val_acc: 0.7778\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 11s 223ms/step - loss: 0.3724 - acc: 0.8760 - val_loss: 0.7091 - val_acc: 0.8222\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.3399 - acc: 0.8952 - val_loss: 1.2601 - val_acc: 0.7333\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.3702 - acc: 0.8808 - val_loss: 0.7625 - val_acc: 0.8000\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 11s 221ms/step - loss: 0.3537 - acc: 0.8799 - val_loss: 0.7462 - val_acc: 0.8000\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.3639 - acc: 0.8778 - val_loss: 0.8852 - val_acc: 0.8222\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.3141 - acc: 0.8882 - val_loss: 1.3034 - val_acc: 0.6889\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 11s 221ms/step - loss: 0.3457 - acc: 0.8814 - val_loss: 1.1639 - val_acc: 0.7333\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.3120 - acc: 0.9045 - val_loss: 1.1369 - val_acc: 0.7556\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.3535 - acc: 0.8776 - val_loss: 0.8668 - val_acc: 0.8222\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 11s 227ms/step - loss: 0.3038 - acc: 0.8929 - val_loss: 0.9545 - val_acc: 0.8000\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 11s 218ms/step - loss: 0.3121 - acc: 0.9071 - val_loss: 0.7202 - val_acc: 0.8444\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.2666 - acc: 0.9180 - val_loss: 1.0645 - val_acc: 0.7778\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.3238 - acc: 0.8941 - val_loss: 0.9855 - val_acc: 0.7778\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.2801 - acc: 0.9062 - val_loss: 0.9848 - val_acc: 0.8000\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.2738 - acc: 0.9164 - val_loss: 1.5357 - val_acc: 0.6667\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 11s 218ms/step - loss: 0.2937 - acc: 0.9071 - val_loss: 1.1247 - val_acc: 0.7333\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.2414 - acc: 0.9235 - val_loss: 1.0630 - val_acc: 0.7556\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 11s 213ms/step - loss: 0.3019 - acc: 0.8960 - val_loss: 1.0824 - val_acc: 0.8000\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.2816 - acc: 0.9000 - val_loss: 0.7310 - val_acc: 0.7778\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.2324 - acc: 0.9227 - val_loss: 1.0570 - val_acc: 0.8000\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.2535 - acc: 0.9101 - val_loss: 0.6095 - val_acc: 0.8222\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 11s 220ms/step - loss: 0.2627 - acc: 0.9103 - val_loss: 1.1699 - val_acc: 0.7778\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.2154 - acc: 0.9319 - val_loss: 0.8624 - val_acc: 0.8000\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.2412 - acc: 0.9256 - val_loss: 0.8385 - val_acc: 0.8222\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.2555 - acc: 0.9213 - val_loss: 0.9661 - val_acc: 0.8000\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.2415 - acc: 0.9193 - val_loss: 0.9903 - val_acc: 0.8000\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1992 - acc: 0.9387 - val_loss: 0.7669 - val_acc: 0.8222\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.2296 - acc: 0.9160 - val_loss: 0.8898 - val_acc: 0.8000\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.2346 - acc: 0.9200 - val_loss: 0.7513 - val_acc: 0.8444\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.1887 - acc: 0.9448 - val_loss: 0.8066 - val_acc: 0.8000\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.2191 - acc: 0.9397 - val_loss: 0.7294 - val_acc: 0.8222\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.2144 - acc: 0.9254 - val_loss: 0.6100 - val_acc: 0.8222\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 11s 213ms/step - loss: 0.1933 - acc: 0.9302 - val_loss: 0.9345 - val_acc: 0.7778\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 11s 229ms/step - loss: 0.2231 - acc: 0.9284 - val_loss: 0.7744 - val_acc: 0.8444\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.1746 - acc: 0.9405 - val_loss: 1.1103 - val_acc: 0.7778\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 11s 213ms/step - loss: 0.2045 - acc: 0.9370 - val_loss: 0.8930 - val_acc: 0.8222\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.2124 - acc: 0.9292 - val_loss: 0.8929 - val_acc: 0.7778\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.1757 - acc: 0.9514 - val_loss: 1.1403 - val_acc: 0.8222\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.1750 - acc: 0.9474 - val_loss: 0.8697 - val_acc: 0.8222\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 11s 220ms/step - loss: 0.1866 - acc: 0.9388 - val_loss: 0.9399 - val_acc: 0.8444\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.1794 - acc: 0.9483 - val_loss: 0.8439 - val_acc: 0.8444\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1539 - acc: 0.9522 - val_loss: 0.7394 - val_acc: 0.8222\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.1406 - acc: 0.9468 - val_loss: 0.9543 - val_acc: 0.8000\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 11s 214ms/step - loss: 0.1832 - acc: 0.9345 - val_loss: 0.9661 - val_acc: 0.8222\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1644 - acc: 0.9401 - val_loss: 0.8338 - val_acc: 0.8222\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 11s 221ms/step - loss: 0.1678 - acc: 0.9491 - val_loss: 0.8525 - val_acc: 0.8000\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.1816 - acc: 0.9393 - val_loss: 0.8659 - val_acc: 0.8444\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.1560 - acc: 0.9480 - val_loss: 0.8132 - val_acc: 0.8444\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.1504 - acc: 0.9597 - val_loss: 1.1959 - val_acc: 0.7778\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.1416 - acc: 0.9486 - val_loss: 1.1894 - val_acc: 0.8000\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1716 - acc: 0.9505 - val_loss: 1.2536 - val_acc: 0.8000\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 11s 218ms/step - loss: 0.1623 - acc: 0.9470 - val_loss: 1.2525 - val_acc: 0.8222\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.1454 - acc: 0.9473 - val_loss: 0.9727 - val_acc: 0.8222\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 11s 213ms/step - loss: 0.1488 - acc: 0.9488 - val_loss: 1.0527 - val_acc: 0.8667\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.1332 - acc: 0.9580 - val_loss: 1.0383 - val_acc: 0.8000\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.1353 - acc: 0.9588 - val_loss: 0.9261 - val_acc: 0.8444\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 11s 213ms/step - loss: 0.1139 - acc: 0.9617 - val_loss: 0.6173 - val_acc: 0.8889\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.1505 - acc: 0.9560 - val_loss: 0.9078 - val_acc: 0.8444\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 11s 221ms/step - loss: 0.1713 - acc: 0.9446 - val_loss: 1.0877 - val_acc: 0.8222\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1283 - acc: 0.9572 - val_loss: 0.8497 - val_acc: 0.8222\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 11s 221ms/step - loss: 0.1448 - acc: 0.9578 - val_loss: 1.0692 - val_acc: 0.8000\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 12s 231ms/step - loss: 0.1302 - acc: 0.9573 - val_loss: 1.5640 - val_acc: 0.8000\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.1372 - acc: 0.9546 - val_loss: 1.7850 - val_acc: 0.8000\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 11s 223ms/step - loss: 0.0992 - acc: 0.9653 - val_loss: 0.9196 - val_acc: 0.8444\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.1337 - acc: 0.9474 - val_loss: 1.0638 - val_acc: 0.8222\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1306 - acc: 0.9592 - val_loss: 0.7366 - val_acc: 0.8667\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.1151 - acc: 0.9598 - val_loss: 0.9670 - val_acc: 0.8444\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.1051 - acc: 0.9709 - val_loss: 0.9882 - val_acc: 0.8000\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.1181 - acc: 0.9573 - val_loss: 1.0553 - val_acc: 0.8444\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.1258 - acc: 0.9561 - val_loss: 1.0687 - val_acc: 0.8222\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.1347 - acc: 0.9580 - val_loss: 1.1040 - val_acc: 0.8444\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.1049 - acc: 0.9678 - val_loss: 1.2353 - val_acc: 0.8444\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.1148 - acc: 0.9621 - val_loss: 0.9793 - val_acc: 0.8444\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.1410 - acc: 0.9547 - val_loss: 0.8255 - val_acc: 0.8667\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1142 - acc: 0.9631 - val_loss: 1.2115 - val_acc: 0.8444\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 11s 221ms/step - loss: 0.0947 - acc: 0.9647 - val_loss: 1.0332 - val_acc: 0.8444\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.1110 - acc: 0.9647 - val_loss: 0.8989 - val_acc: 0.8444\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 11s 210ms/step - loss: 0.1045 - acc: 0.9678 - val_loss: 0.9041 - val_acc: 0.8667\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.0957 - acc: 0.9666 - val_loss: 0.9032 - val_acc: 0.8444\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.0879 - acc: 0.9719 - val_loss: 0.8536 - val_acc: 0.8667\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 11s 211ms/step - loss: 0.1345 - acc: 0.9562 - val_loss: 0.8803 - val_acc: 0.8444\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.1251 - acc: 0.9568 - val_loss: 1.2056 - val_acc: 0.8000\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 11s 215ms/step - loss: 0.0918 - acc: 0.9685 - val_loss: 0.9750 - val_acc: 0.8444\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.1041 - acc: 0.9689 - val_loss: 1.3479 - val_acc: 0.8000\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.1056 - acc: 0.9618 - val_loss: 0.9025 - val_acc: 0.8667\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 11s 217ms/step - loss: 0.1447 - acc: 0.9603 - val_loss: 0.7505 - val_acc: 0.8444\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 10s 209ms/step - loss: 0.0876 - acc: 0.9703 - val_loss: 0.7722 - val_acc: 0.8889\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 11s 221ms/step - loss: 0.1174 - acc: 0.9612 - val_loss: 0.9759 - val_acc: 0.8667\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 11s 219ms/step - loss: 0.1236 - acc: 0.9600 - val_loss: 1.0423 - val_acc: 0.8667\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 11s 212ms/step - loss: 0.0981 - acc: 0.9642 - val_loss: 0.9845 - val_acc: 0.8444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzrRJxGDHGGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a8d3ef24-de46-46f3-ef0a-01f9404d1615"
      },
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir, \n",
        "    target_size=(150,150), \n",
        "    batch_size=32, \n",
        "    class_mode='categorical')\n",
        "\n",
        "model.evaluate(test_generator)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 45 images belonging to 15 classes.\n",
            "2/2 [==============================] - 0s 57ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4233826133939955, 0.9111111150847541]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    }
  ]
}